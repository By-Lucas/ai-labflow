{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "id": "vOISp5PYq4qi",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(model_name='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os documentos\n",
    "loader = TextLoader('base_conhecimento_britadeira.txt')\n",
    "documents = loader.load()\n",
    "# Carregar histórico de conversas \n",
    "historico_conversas = \"\"\"Cliente: Minha britadeira não liga. Chatbot: Você já verificou \n",
    "                         se a bateria está carregada e conectada corretamente?\"\"\"\n",
    "# Pergunta do cliente\n",
    "pergunta = \"Minha britadeira não liga. Eu já veriquei e a bateria está carregada e conectada corretamente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"context\": \"\\n\".join(doc.page_content for doc in documents),\n",
    "    \"question\": pergunta,\n",
    "    \"historico\": historico_conversas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base_conhecimento = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Use o seguinte contexto para responder à pergunta. \n",
    "    Responda apenas com base nas informações fornecidas.\n",
    "    Não forneceça instruções de procedimento já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Contexto: {context}\n",
    "    Pergunta: {question}\"\"\"\n",
    ")\n",
    "prompt_historico_conversas = PromptTemplate(\n",
    "    input_variables=[\"historico\", \"question\"],\n",
    "    template=\"\"\"Use o histórico de conversas para responder à pergunta. \n",
    "    Responda apenas com base nas informações fornecidas. \n",
    "    Não forneceça instruções de procedimento já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Histórico: {historico}\n",
    "    Pergunta: {question}\"\"\"\n",
    ")\n",
    "prompt_final = PromptTemplate(\n",
    "    input_variables=[\"resposta_base_conhecimento\", \"resposta_historico_conversas\"],\n",
    "    template=\"\"\"Combine as seguintes respostas para gerar uma resposta final,\n",
    "    mas não forneça instruções de procedimentos já realizados:\n",
    "    Resposta da base de conhecimento: {resposta_base_conhecimento}\n",
    "    Resposta do histórico de conversas: {resposta_historico_conversas}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='Use o seguinte contexto para responder à pergunta. \\n    Responda apenas com base nas informações fornecidas.\\n    Não forneceça instruções de procedimento já realizados.\\n    Não utilize informações externas ao contexto:\\n    Contexto: {context}\\n    Pergunta: {question}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as cadeias  \n",
    "chain_base_conhecimento = prompt_base_conhecimento | openai\n",
    "chain_historico_conversas = prompt_historico_conversas | openai\n",
    "chain_final = prompt_final | openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['context', 'question'], template='Use o seguinte contexto para responder à pergunta. \\n    Responda apenas com base nas informações fornecidas.\\n    Não forneceça instruções de procedimento já realizados.\\n    Não utilize informações externas ao contexto:\\n    Contexto: {context}\\n    Pergunta: {question}') last=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9f7d7ec9d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9f7d57c2d0>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n"
     ]
    }
   ],
   "source": [
    "print(chain_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['historico', 'question'], template='Use o histórico de conversas para responder à pergunta. \\n    Responda apenas com base nas informações fornecidas. \\n    Não forneceça instruções de procedimento já realizados.\\n    Não utilize informações externas ao contexto:\\n    Histórico: {historico}\\n    Pergunta: {question}') last=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9f7d7ec9d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9f7d57c2d0>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n"
     ]
    }
   ],
   "source": [
    "print(chain_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando dados e executando\n",
    "resultado_base_conhecimento = chain_base_conhecimento.invoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]})\n",
    "resultado_historico_conversas = chain_historico_conversas.invoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "resultado_final = chain_final.invoke({\"resposta_base_conhecimento\": resultado_base_conhecimento, \n",
    "                                      \"resposta_historico_conversas\": resultado_historico_conversas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Base de Conhecimento:\n",
      " content='Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.' response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 681, 'total_tokens': 733, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None} id='run-e98007cf-6f5f-49f5-a91b-97339ad47c9e-0' usage_metadata={'input_tokens': 681, 'output_tokens': 52, 'total_tokens': 733}\n",
      "----\n",
      "Resultado Histórico de Conversas:\n",
      " content='Você já verificou se há algum problema com o interruptor de ligar/desligar ou se há algum dano visível nos cabos ou conectores?' response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 106, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None} id='run-891f5062-c3bc-4ede-82ec-034eb46f5abf-0' usage_metadata={'input_tokens': 106, 'output_tokens': 31, 'total_tokens': 137}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultado Base de Conhecimento:\\n\", resultado_base_conhecimento)\n",
    "print(\"----\")\n",
    "print(\"Resultado Histórico de Conversas:\\n\", resultado_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta e se há algum problema com ele ou danos visíveis nos cabos ou conectores. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta e se há algum problema com ele ou danos visíveis nos cabos ou conectores. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.' response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 493, 'total_tokens': 562, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-2921e5be-5f96-4c43-adc9-0baca7a7215b-0' usage_metadata={'input_tokens': 493, 'output_tokens': 69, 'total_tokens': 562}\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
