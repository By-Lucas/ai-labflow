{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "id": "ASzXPwDRUBxA",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI,OpenAI\n",
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eCBl659lZl7j"
   },
   "outputs": [],
   "source": [
    "template = '''\n",
    "Você é um analista financeiro.\n",
    "Escreva um relatório financeiro detalhado para a empresa \"{empresa}\" para o período {periodo}.\n",
    "\n",
    "O relatório deve ser escrito em {idioma} e incluir as seguintes análises:\n",
    "{analises}\n",
    "\n",
    "Certifique-se de fornecer insights e conclusões para cada seção.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zCezS4xvZl_C"
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z_YBQfANZmCi"
   },
   "outputs": [],
   "source": [
    "empresa = 'ACME Corp'\n",
    "periodo = 'Q1 2024'\n",
    "idioma = 'Português'\n",
    "analises = [\n",
    "    \"Análise do Balanço Patrimonial\",\n",
    "    \"Análise do Fluxo de Caixa\",\n",
    "    \"Análise de Tendências\",\n",
    "    \"Análise de Receita e Lucro\",\n",
    "    \"Análise de Posição de Mercado\"\n",
    "]\n",
    "analises_text = \"\\n\".join([f\"- {analise}\" for analise in analises])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Análise do Balanço Patrimonial\n",
      "- Análise do Fluxo de Caixa\n",
      "- Análise de Tendências\n",
      "- Análise de Receita e Lucro\n",
      "- Análise de Posição de Mercado\n"
     ]
    }
   ],
   "source": [
    "print(analises_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C9tfTCDZuXr",
    "outputId": "f57170e1-95ff-4fb4-b080-c9dd7ae2b610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Gerado:\n",
      " \n",
      "Você é um analista financeiro.\n",
      "Escreva um relatório financeiro detalhado para a empresa \"ACME Corp\" para o período Q1 2024.\n",
      "\n",
      "O relatório deve ser escrito em Português e incluir as seguintes análises:\n",
      "- Análise do Balanço Patrimonial\n",
      "- Análise do Fluxo de Caixa\n",
      "- Análise de Tendências\n",
      "- Análise de Receita e Lucro\n",
      "- Análise de Posição de Mercado\n",
      "\n",
      "Certifique-se de fornecer insights e conclusões para cada seção.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(\n",
    "    empresa=empresa,\n",
    "    periodo=periodo,\n",
    "    idioma=idioma,\n",
    "    analises=analises_text\n",
    ")\n",
    "print(\"Prompt Gerado:\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBYz28rrYyXd",
    "outputId": "a5e593fb-f02d-4217-9c91-99900817902c"
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m openai = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpt-3.5-turbo-instruct\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#max 4096\u001b[39;00m\n\u001b[32m      3\u001b[39m response = openai.invoke(prompt)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaída do LLM:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Área de trabalho/TK Global Technology/Cursos AI/3 Formacao 2025/.venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:113\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    112\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Área de trabalho/TK Global Technology/Cursos AI/3 Formacao 2025/.venv/lib/python3.11/site-packages/pydantic/v1/main.py:347\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(__pydantic_self__, **data)\u001b[39m\n\u001b[32m    345\u001b[39m values, fields_set, validation_error = validate_model(__pydantic_self__.\u001b[34m__class__\u001b[39m, data)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    349\u001b[39m     object_setattr(__pydantic_self__, \u001b[33m'\u001b[39m\u001b[33m__dict__\u001b[39m\u001b[33m'\u001b[39m, values)\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "openai = OpenAI(model_name='gpt-3.5-turbo-instruct',max_tokens=2000) #max 4096\n",
    "\n",
    "response = openai.invoke(prompt)\n",
    "print(\"Saída do LLM:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGQUp499fKBZ"
   },
   "outputs": [],
   "source": [
    "#equivalência aos roles: system: system, Human: user, AI: assistant\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='Você deve estruturar suas respostas de acordo com o método de análise de negócios, garantindo clareza e concisão.'),\n",
    "        HumanMessagePromptTemplate.from_template('Por favor, gere um relatório detalhado sobre a indústria de tecnologia na região \"{regiao}\".'),\n",
    "        AIMessage(content='Claro, vou começar coletando informações sobre a região e analisando os dados disponíveis.'),\n",
    "        HumanMessage(content='Certifique-se de incluir uma análise SWOT e uma previsão de crescimento para os próximos 5 anos.'),\n",
    "        AIMessage(content='Entendido. Aqui está o relatório completo:')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDxgxLrofKEc",
    "outputId": "a3e79711-b163-4824-fed8-0f2c399a4b3f"
   },
   "outputs": [],
   "source": [
    "prompt_gerado = chat_template.format_messages(regiao='América Latina')\n",
    "print(prompt_gerado)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "daEu9my2fKHm",
    "outputId": "aeeb4f0b-a4bd-4596-c5b3-affc6b8e3426",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "response = openai.invoke(prompt_gerado)\n",
    "print(\"Saída do LLM:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
